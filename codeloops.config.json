{
  "version": "1.0.0",
  "default_model": "openai.gpt-4o-mini",
  "anthropic": {
    "_comment": "api_key can be set via ANTHROPIC_API_KEY env var",
    "models": {
      "haiku": {
        "id": "claude-3-haiku-20240307",
        "max_tokens": 4096,
        "description": "Fast, lightweight model for simple tasks"
      },
      "sonnet": {
        "id": "claude-3-5-sonnet-20241022", 
        "max_tokens": 8192,
        "description": "Balanced model for most tasks"
      },
      "opus": {
        "id": "claude-3-opus-20240229",
        "max_tokens": 4096,
        "description": "Most capable model for complex tasks"
      }
    }
  },
  "openai": {
    "_comment": "api_key can be set via OPENAI_API_KEY env var",
    "models": {
      "gpt-4o": {
        "id": "gpt-4o",
        "max_tokens": 4096,
        "description": "Latest GPT-4 Omni model"
      },
      "gpt-4o-mini": {
        "id": "gpt-4o-mini",
        "max_tokens": 16384,
        "description": "Smaller, faster GPT-4 model"
      },
      "o1-preview": {
        "id": "o1-preview",
        "max_tokens": 32768,
        "reasoning_effort": "medium",
        "description": "Reasoning model for complex problems"
      },
      "o1-mini": {
        "id": "o1-mini",
        "max_tokens": 65536,
        "reasoning_effort": "low",
        "description": "Smaller reasoning model"
      }
    }
  },
  "azure": {
    "_comment": "See documentation for Azure OpenAI configuration options",
    "models": {
      "_comment": "Models configured through Azure deployments"
    }
  },
  "deepseek": {
    "_comment": "api_key can be set via DEEPSEEK_API_KEY env var",
    "models": {
      "deepseek-chat": {
        "id": "deepseek-chat",
        "max_tokens": 4096,
        "description": "DeepSeek chat model"
      }
    }
  },
  "google": {
    "_comment": "api_key can be set via GOOGLE_API_KEY env var",
    "models": {
      "gemini-pro": {
        "id": "gemini-pro",
        "max_tokens": 2048,
        "description": "Google Gemini Pro model"
      }
    }
  },
  "openrouter": {
    "_comment": "api_key can be set via OPENROUTER_API_KEY env var",
    "models": {
      "_comment": "OpenRouter provides access to multiple models"
    }
  },
  "generic": {
    "_comment": "For Ollama or other OpenAI-compatible APIs",
    "api_key": "ollama",
    "base_url": "http://localhost:11434/v1",
    "models": {
      "llama3": {
        "id": "llama3",
        "max_tokens": 4096,
        "description": "Llama 3 model via Ollama"
      }
    }
  },
  "tensorzero": {
    "models": {}
  },
  "agents": {
    "critic": {
      "enabled": true,
      "model": "anthropic.sonnet",
      "temperature": 0.3,
      "max_tokens": 2000,
      "_comment": "Use Sonnet for balanced performance in code review"
    },
    "summarizer": {
      "enabled": true,
      "model": "anthropic.haiku",
      "temperature": 0.5,
      "max_tokens": 1000,
      "_comment": "Use Haiku for fast summarization tasks"
    },
    "actor": {
      "enabled": true,
      "model": "default",
      "temperature": 0.7,
      "_comment": "Use default model for general actor tasks"
    }
  },
  "mcp": {
    "servers": {}
  },
  "telemetry": {
    "enabled": true,
    "service_name": "codeloops",
    "service_version": "1.0.0",
    "environment": "development",
    "opentelemetry": {
      "enabled": true,
      "otlp_endpoint": "http://localhost:4318",
      "sample_rate": 1.0
    },
    "metrics": {
      "enabled": true
    }
  },
  "logging": {
    "level": "info",
    "format": "json",
    "destination": "stdout",
    "pino": {
      "pretty_print": false,
      "redact": ["*.api_key", "*.password", "*.secret"]
    },
    "file_logging": {
      "enabled": false,
      "path": "./logs/codeloops.log"
    }
  },
  "codeloops": {
    "knowledge_graph": {
      "data_dir": "./data",
      "file_format": "ndjson",
      "auto_backup": true,
      "backup_interval": 3600,
      "max_nodes_per_project": 10000
    },
  },
  "features": {
    "use_voltagent": false,
    "legacy_python_agents": true
  },
  "env_prefix": "CODELOOPS"
}